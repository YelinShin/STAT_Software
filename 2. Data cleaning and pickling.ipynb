{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cheack whether an object (data) contains attribute (x) or not\n",
    "def check_var(data, x) :\n",
    "    try :\n",
    "        data[x]\n",
    "        return True\n",
    "    except :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopset = stopwords.words(\"english\") + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to turn json into dataframe\n",
    "def json_to_df(all_file, hashtag) :\n",
    "# we only keep text and hashtags\n",
    "    df_list = []\n",
    "    text_set = set()\n",
    "    for file in all_file :\n",
    "        with open(file, 'r', encoding = 'utf8') as f :\n",
    "            all_data = json.load(f)\n",
    "     \n",
    "            for data in all_data :\n",
    "                hashtag_list = [] # to collect list of hashtags\n",
    "            \n",
    "                # case 1: check whether it is a retweet data or not\n",
    "                if (check_var(data, 'retweeted_status')) :\n",
    "                \n",
    "                    Text = data['retweeted_status']['full_text']\n",
    "                    for t in data['retweeted_status']['entities']['hashtags'] :\n",
    "                        hashtag_list.append(t['text'])                \n",
    "\n",
    "                    # check whether it is retweet of quoted tweet or not\n",
    "                    if (check_var(data['retweeted_status'], 'quoted_status')) :\n",
    "                        Text = Text + ' || ' + data['retweeted_status']['quoted_status']['full_text']\n",
    "                        for t in data['retweeted_status']['entities']['hashtags'] :\n",
    "                            hashtag_list.append(t['text'])               \n",
    " \n",
    "                # case 2: check whether it is a quote tweet data or not\n",
    "                elif (check_var(data, 'quoted_status')) :\n",
    "                    Text = data['full_text'] \n",
    "                    Text = Text + ' || ' + data['quoted_status']['full_text']\n",
    "                    for t in data['entities']['hashtags'] :\n",
    "                        hashtag_list.append(t['text'])\n",
    "                    for t in data['quoted_status']['entities']['hashtags'] :\n",
    "                        hashtag_list.append(t['text'])\n",
    "\n",
    "                # if it does not belong to case 1 and case 2, it is an ordinary tweet data\n",
    "                else :\n",
    "                    Text = data['full_text']\n",
    "                    for t in data['entities']['hashtags'] :\n",
    "                        hashtag_list.append(t['text'])\n",
    "            \n",
    "                hashtag_list = [h.lower() for h in hashtag_list]\n",
    "                hashtag_list = [h for h in hashtag_list if h != hashtag] # remove our hashtag from hashtag_list  \n",
    "            \n",
    "                Text = remove_emoji(Text) # remove emoji\n",
    "                Text = re.sub(\"[-/]\", \" \", Text) # substitute dash and slash with space       \n",
    "            \n",
    "                text_split = Text.lower().split() # split string into list\n",
    "            \n",
    "                remove_list = []\n",
    "                for t in text_split :\n",
    "                    if hashtag in t : # remove all words containing our hashtag\n",
    "                        remove_list.append(t)\n",
    "                    if 'http' in t : # remove link\n",
    "                        remove_list.append(t)\n",
    "                    if '@' in t : # remove ...@...\n",
    "                        remove_list.append(t)\n",
    "                    if t == '\\n' : # remove new line character\n",
    "                        remove_list.append(t)\n",
    "                text_split = [t for t in text_split if t not in remove_list]                          \n",
    "                        \n",
    "                for i in range(len(text_split)) :\n",
    "                    t = text_split[i]\n",
    "                    if t.startswith(\"'\") or t.startswith('\"') : # remove quotation mark\n",
    "                        text_split[i] = t[1:] \n",
    "                    if t.endswith(\"'\") or t.endswith('\"') : \n",
    "                        text_split[i] = t[:len(t) - 1]         \n",
    "                    text_split[i] = re.sub(\"[^a-z']\", \"\", t)\n",
    "\n",
    "                # if text contains only stop words, we will not keep it in our dataframe\n",
    "                words = [t for t in text_split if t not in stopset]  \n",
    "                if len(words) == 0 : \n",
    "                    continue \n",
    "            \n",
    "                Text = ' '.join(text_split) # join the list back to string\n",
    "            \n",
    "                for h in hashtag_list :\n",
    "                    Text = Text.replace('#' + h.lower(), h.lower()) # for other hashtags, we change them to words \n",
    "            \n",
    "                if Text not in text_set : # check whether new data has already been kept in our list or not\n",
    "                    df_list.append((Text, hashtag_list))  \n",
    "                    text_set.add(Text)\n",
    "\n",
    "    df = pd.DataFrame(df_list, columns = ['Text', 'Hashtag'])\n",
    "    df['Classification'] = [hashtag] * df.shape[0]\n",
    "    df = df[['Classification', 'Text', 'Hashtag']]\n",
    "                    \n",
    "    return df                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string) :\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags = re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'christmas-out-23K.json'\n",
    "file2 = 'christmas-out-15K.json'\n",
    "christmas_df = json_to_df([file1, file2], 'christmas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>christmas</td>\n",
       "      <td>tco tsrcaibt is the perfect place for the holi...</td>\n",
       "      <td>[coldpresssoap, bodyscrub, soap, soapmaking, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>christmas</td>\n",
       "      <td>follow amp retweet for the chance to win a  jo...</td>\n",
       "      <td>[competition, win]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christmas</td>\n",
       "      <td>it's winitwednesday follow amp rt amp to win t...</td>\n",
       "      <td>[winitwednesday, win, astreetcatnamedbob, comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christmas</td>\n",
       "      <td>there will be obstacles there will be doubters...</td>\n",
       "      <td>[cryptocurrency, binary, motivation, investor,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>christmas</td>\n",
       "      <td>do you know how i plan to celebrate this year ...</td>\n",
       "      <td>[durgapuja, diwali]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18780</th>\n",
       "      <td>christmas</td>\n",
       "      <td>thanks so much  also have a carol concert toni...</td>\n",
       "      <td>[concert, virtualevents, biggive2020, christma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18781</th>\n",
       "      <td>christmas</td>\n",
       "      <td>make positive use of this yuletide season be a...</td>\n",
       "      <td>[december, cybersecurity, google, tuesdaymotiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18782</th>\n",
       "      <td>christmas</td>\n",
       "      <td>calling  love this vintage phone and for more ...</td>\n",
       "      <td>[calling, love, vintage, phone, unique]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18783</th>\n",
       "      <td>christmas</td>\n",
       "      <td>new earl the squirrel coffee mug universal stu...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18784</th>\n",
       "      <td>christmas</td>\n",
       "      <td>check out our festive giftguide for ways to su...</td>\n",
       "      <td>[giftguide, blackowned, foaki]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18785 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classification                                               Text  \\\n",
       "0          christmas  tco tsrcaibt is the perfect place for the holi...   \n",
       "1          christmas  follow amp retweet for the chance to win a  jo...   \n",
       "2          christmas  it's winitwednesday follow amp rt amp to win t...   \n",
       "3          christmas  there will be obstacles there will be doubters...   \n",
       "4          christmas  do you know how i plan to celebrate this year ...   \n",
       "...              ...                                                ...   \n",
       "18780      christmas  thanks so much  also have a carol concert toni...   \n",
       "18781      christmas  make positive use of this yuletide season be a...   \n",
       "18782      christmas  calling  love this vintage phone and for more ...   \n",
       "18783      christmas  new earl the squirrel coffee mug universal stu...   \n",
       "18784      christmas  check out our festive giftguide for ways to su...   \n",
       "\n",
       "                                                 Hashtag  \n",
       "0      [coldpresssoap, bodyscrub, soap, soapmaking, e...  \n",
       "1                                     [competition, win]  \n",
       "2      [winitwednesday, win, astreetcatnamedbob, comp...  \n",
       "3      [cryptocurrency, binary, motivation, investor,...  \n",
       "4                                    [durgapuja, diwali]  \n",
       "...                                                  ...  \n",
       "18780  [concert, virtualevents, biggive2020, christma...  \n",
       "18781  [december, cybersecurity, google, tuesdaymotiv...  \n",
       "18782            [calling, love, vintage, phone, unique]  \n",
       "18783                                                 []  \n",
       "18784                     [giftguide, blackowned, foaki]  \n",
       "\n",
       "[18785 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "christmas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'covid-out-23K.json'\n",
    "file2 = 'covid-out-15K.json'\n",
    "covid_df = json_to_df([file1, file2], 'covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid</td>\n",
       "      <td>when i wonder how long well be in lockdown i t...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid</td>\n",
       "      <td>so if a cure for has been found in just a few ...</td>\n",
       "      <td>[cancer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid</td>\n",
       "      <td>us  deaths  plus source coronavirus resource c...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid</td>\n",
       "      <td>why schools closing and bars restaurants and g...</td>\n",
       "      <td>[nyc, schools]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid</td>\n",
       "      <td>my great aunt died this evening of at the age ...</td>\n",
       "      <td>[covid_19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17933</th>\n",
       "      <td>covid</td>\n",
       "      <td>here at tco eciaduveq we've got some new stays...</td>\n",
       "      <td>[staysafe, shopping, holidayshopping, shop, ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17934</th>\n",
       "      <td>covid</td>\n",
       "      <td>apple iwatch repair visit our site tco swiudcz...</td>\n",
       "      <td>[melbournemobilephonereapirs, mmpr, covid19, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17935</th>\n",
       "      <td>covid</td>\n",
       "      <td>to keep moving forward we must look back in  f...</td>\n",
       "      <td>[culture, reconnection, onlineevent, teamboost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17936</th>\n",
       "      <td>covid</td>\n",
       "      <td>has disproportionately grown the education ga...</td>\n",
       "      <td>[ocfgrowingminds]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17937</th>\n",
       "      <td>covid</td>\n",
       "      <td>concern about environement has raised for sout...</td>\n",
       "      <td>[publicopinion]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17938 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classification                                               Text  \\\n",
       "0              covid  when i wonder how long well be in lockdown i t...   \n",
       "1              covid  so if a cure for has been found in just a few ...   \n",
       "2              covid  us  deaths  plus source coronavirus resource c...   \n",
       "3              covid  why schools closing and bars restaurants and g...   \n",
       "4              covid  my great aunt died this evening of at the age ...   \n",
       "...              ...                                                ...   \n",
       "17933          covid  here at tco eciaduveq we've got some new stays...   \n",
       "17934          covid  apple iwatch repair visit our site tco swiudcz...   \n",
       "17935          covid  to keep moving forward we must look back in  f...   \n",
       "17936          covid   has disproportionately grown the education ga...   \n",
       "17937          covid  concern about environement has raised for sout...   \n",
       "\n",
       "                                                 Hashtag  \n",
       "0                                                     []  \n",
       "1                                               [cancer]  \n",
       "2                                                     []  \n",
       "3                                         [nyc, schools]  \n",
       "4                                             [covid_19]  \n",
       "...                                                  ...  \n",
       "17933  [staysafe, shopping, holidayshopping, shop, ac...  \n",
       "17934  [melbournemobilephonereapirs, mmpr, covid19, m...  \n",
       "17935  [culture, reconnection, onlineevent, teamboost...  \n",
       "17936                                  [ocfgrowingminds]  \n",
       "17937                                    [publicopinion]  \n",
       "\n",
       "[17938 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'spacex-out-35K.json'\n",
    "file2 = 'spacex-out-20K.json'\n",
    "spacex_df = json_to_df([file1, file2], 'spacex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spacex</td>\n",
       "      <td>the return of crew 's booster b after changing...</td>\n",
       "      <td>[crew2, spacexfleet, crew1, launchamerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spacex</td>\n",
       "      <td>weather for nov st at pm est  pm pst  nov nd a...</td>\n",
       "      <td>[starlink, falcon9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spacex</td>\n",
       "      <td>falcon  landing  by harv nft cryptoart tco jdw...</td>\n",
       "      <td>[nft, cryptoart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spacex</td>\n",
       "      <td>moonship crew section moonship tco ajhwmihpzm</td>\n",
       "      <td>[moonship]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spacex</td>\n",
       "      <td>looks like the left leg's crush core wasn't th...</td>\n",
       "      <td>[spacexfleet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12467</th>\n",
       "      <td>spacex</td>\n",
       "      <td>starlink will get a much needed feature usabil...</td>\n",
       "      <td>[usability]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12468</th>\n",
       "      <td>spacex</td>\n",
       "      <td>no clouds in the sky  degrees awesome time at ...</td>\n",
       "      <td>[kennedyspacecenter, falcon9, rocket]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12469</th>\n",
       "      <td>spacex</td>\n",
       "      <td>nasa astronaut is sleeping in the cockpit of c...</td>\n",
       "      <td>[nasa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12470</th>\n",
       "      <td>spacex</td>\n",
       "      <td>space the final frontier tco yfpcygabo  lagoon...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12471</th>\n",
       "      <td>spacex</td>\n",
       "      <td>just incredible the scientists and engineers t...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12472 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classification                                               Text  \\\n",
       "0             spacex  the return of crew 's booster b after changing...   \n",
       "1             spacex  weather for nov st at pm est  pm pst  nov nd a...   \n",
       "2             spacex  falcon  landing  by harv nft cryptoart tco jdw...   \n",
       "3             spacex      moonship crew section moonship tco ajhwmihpzm   \n",
       "4             spacex  looks like the left leg's crush core wasn't th...   \n",
       "...              ...                                                ...   \n",
       "12467         spacex  starlink will get a much needed feature usabil...   \n",
       "12468         spacex  no clouds in the sky  degrees awesome time at ...   \n",
       "12469         spacex  nasa astronaut is sleeping in the cockpit of c...   \n",
       "12470         spacex  space the final frontier tco yfpcygabo  lagoon...   \n",
       "12471         spacex  just incredible the scientists and engineers t...   \n",
       "\n",
       "                                          Hashtag  \n",
       "0      [crew2, spacexfleet, crew1, launchamerica]  \n",
       "1                             [starlink, falcon9]  \n",
       "2                                [nft, cryptoart]  \n",
       "3                                      [moonship]  \n",
       "4                                   [spacexfleet]  \n",
       "...                                           ...  \n",
       "12467                                 [usability]  \n",
       "12468       [kennedyspacecenter, falcon9, rocket]  \n",
       "12469                                      [nasa]  \n",
       "12470                                          []  \n",
       "12471                                          []  \n",
       "\n",
       "[12472 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacex_df = spacex_df.sample(n = 12000) \n",
    "christmas_df = christmas_df.sample(n = 12000) \n",
    "covid_df = covid_df.sample(n = 12000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>spacex</td>\n",
       "      <td>the crew is on track to lift off from cape can...</td>\n",
       "      <td>[crew1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11373</th>\n",
       "      <td>spacex</td>\n",
       "      <td>tco hzpifdto brand new paperback in the mark n...</td>\n",
       "      <td>[paperback, book, sciencefiction, sfgiants, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6727</th>\n",
       "      <td>spacex</td>\n",
       "      <td>this is amazing the amount of energy used for ...</td>\n",
       "      <td>[energy, spacelaunchlive, launchamerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11951</th>\n",
       "      <td>spacex</td>\n",
       "      <td>our tools are widely used in the aerospace and...</td>\n",
       "      <td>[aviation, aerospace, boeing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8278</th>\n",
       "      <td>spacex</td>\n",
       "      <td>leak check is good gooooaaaalllllll launchamer...</td>\n",
       "      <td>[launchamerica, nasa, crew1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6346</th>\n",
       "      <td>spacex</td>\n",
       "      <td>reentry burn on the falcon first stage nasa cr...</td>\n",
       "      <td>[nasa, crew1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>spacex</td>\n",
       "      <td>the run into tesla's addition next month may s...</td>\n",
       "      <td>[tesla, tsla, elonmusk, teslamotors, teslamode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>spacex</td>\n",
       "      <td>me building a makeshift telescope with x zoom ...</td>\n",
       "      <td>[nasasocial, nasa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>spacex</td>\n",
       "      <td>minutes to launch nasa tco flsbsmzl  polls ar...</td>\n",
       "      <td>[nasa, nasa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7332</th>\n",
       "      <td>spacex</td>\n",
       "      <td>too exciting launchamerica crew</td>\n",
       "      <td>[launchamerica, crew1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classification                                               Text  \\\n",
       "7428          spacex  the crew is on track to lift off from cape can...   \n",
       "11373         spacex  tco hzpifdto brand new paperback in the mark n...   \n",
       "6727          spacex  this is amazing the amount of energy used for ...   \n",
       "11951         spacex  our tools are widely used in the aerospace and...   \n",
       "8278          spacex  leak check is good gooooaaaalllllll launchamer...   \n",
       "...              ...                                                ...   \n",
       "6346          spacex  reentry burn on the falcon first stage nasa cr...   \n",
       "1358          spacex  the run into tesla's addition next month may s...   \n",
       "8959          spacex  me building a makeshift telescope with x zoom ...   \n",
       "7913          spacex   minutes to launch nasa tco flsbsmzl  polls ar...   \n",
       "7332          spacex                    too exciting launchamerica crew   \n",
       "\n",
       "                                                 Hashtag  \n",
       "7428                                             [crew1]  \n",
       "11373  [paperback, book, sciencefiction, sfgiants, ha...  \n",
       "6727            [energy, spacelaunchlive, launchamerica]  \n",
       "11951                      [aviation, aerospace, boeing]  \n",
       "8278                        [launchamerica, nasa, crew1]  \n",
       "...                                                  ...  \n",
       "6346                                       [nasa, crew1]  \n",
       "1358   [tesla, tsla, elonmusk, teslamotors, teslamode...  \n",
       "8959                                  [nasasocial, nasa]  \n",
       "7913                                        [nasa, nasa]  \n",
       "7332                              [launchamerica, crew1]  \n",
       "\n",
       "[12000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12503</th>\n",
       "      <td>christmas</td>\n",
       "      <td>live pm est hi december vibes shreddin tha slo...</td>\n",
       "      <td>[steep, snowday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8819</th>\n",
       "      <td>christmas</td>\n",
       "      <td>charming miniature door wreath for vour dollho...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11638</th>\n",
       "      <td>christmas</td>\n",
       "      <td>in the midst of the snow storm and winter in h...</td>\n",
       "      <td>[tuesdaytune, tistheseason, forgiving, tagsfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>christmas</td>\n",
       "      <td>usborne books hosted a book fair benefitting c...</td>\n",
       "      <td>[usbornebooks, casa, books]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13382</th>\n",
       "      <td>christmas</td>\n",
       "      <td>fantastic bbc tv schedulefor subscribers tco v...</td>\n",
       "      <td>[bbc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8964</th>\n",
       "      <td>christmas</td>\n",
       "      <td>who will have the balls to send out the first ...</td>\n",
       "      <td>[holidaycard, greetingcards, holidaygreetingca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14094</th>\n",
       "      <td>christmas</td>\n",
       "      <td>graboids love tco edqbhb</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10480</th>\n",
       "      <td>christmas</td>\n",
       "      <td>gift peter rabbit savings jar spending money j...</td>\n",
       "      <td>[peter, etsy, gift]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16616</th>\n",
       "      <td>christmas</td>\n",
       "      <td>nothing wrong with this movie tco mmqfkmlx tco...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>christmas</td>\n",
       "      <td>cool royalconnectionhour now just to work out ...</td>\n",
       "      <td>[royalconnectionhour]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classification                                               Text  \\\n",
       "12503      christmas  live pm est hi december vibes shreddin tha slo...   \n",
       "8819       christmas  charming miniature door wreath for vour dollho...   \n",
       "11638      christmas  in the midst of the snow storm and winter in h...   \n",
       "864        christmas  usborne books hosted a book fair benefitting c...   \n",
       "13382      christmas  fantastic bbc tv schedulefor subscribers tco v...   \n",
       "...              ...                                                ...   \n",
       "8964       christmas  who will have the balls to send out the first ...   \n",
       "14094      christmas                           graboids love tco edqbhb   \n",
       "10480      christmas  gift peter rabbit savings jar spending money j...   \n",
       "16616      christmas  nothing wrong with this movie tco mmqfkmlx tco...   \n",
       "1205       christmas  cool royalconnectionhour now just to work out ...   \n",
       "\n",
       "                                                 Hashtag  \n",
       "12503                                   [steep, snowday]  \n",
       "8819                                                  []  \n",
       "11638  [tuesdaytune, tistheseason, forgiving, tagsfor...  \n",
       "864                          [usbornebooks, casa, books]  \n",
       "13382                                              [bbc]  \n",
       "...                                                  ...  \n",
       "8964   [holidaycard, greetingcards, holidaygreetingca...  \n",
       "14094                                                 []  \n",
       "10480                                [peter, etsy, gift]  \n",
       "16616                                                 []  \n",
       "1205                               [royalconnectionhour]  \n",
       "\n",
       "[12000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "christmas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>covid</td>\n",
       "      <td>hello i am a professional logo designer if you...</td>\n",
       "      <td>[eijazkhan, bitcoin, blackpink, blockchain, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>covid</td>\n",
       "      <td>at the old lab shared office space we were alw...</td>\n",
       "      <td>[covidpiggybacking, coviduk, comorbidity, asym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13282</th>\n",
       "      <td>covid</td>\n",
       "      <td>disaster relief loan funding program for busin...</td>\n",
       "      <td>[relief, businesses, relieffunding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>covid</td>\n",
       "      <td>why is one of your hospice directors still emp...</td>\n",
       "      <td>[coronavirus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13204</th>\n",
       "      <td>covid</td>\n",
       "      <td>is your eligibility towards permanentresidence...</td>\n",
       "      <td>[permanentresidence, covid19, pnp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>covid</td>\n",
       "      <td>love and kindness are never wasted beyondright...</td>\n",
       "      <td>[beyondrights, charity, nonprofit, donate, lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964</th>\n",
       "      <td>covid</td>\n",
       "      <td>people on my shit list for lying denying reali...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4339</th>\n",
       "      <td>covid</td>\n",
       "      <td>is there a connection between air pollution an...</td>\n",
       "      <td>[airpollution, pollution, covid19, coronavirus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>covid</td>\n",
       "      <td>icymi the loser whos barricaded himself in the...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>covid</td>\n",
       "      <td>now is the time to start preparing your facili...</td>\n",
       "      <td>[facility, vaccine, drive, clinics, pharmacies...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classification                                               Text  \\\n",
       "9890           covid  hello i am a professional logo designer if you...   \n",
       "839            covid  at the old lab shared office space we were alw...   \n",
       "13282          covid  disaster relief loan funding program for busin...   \n",
       "15000          covid  why is one of your hospice directors still emp...   \n",
       "13204          covid  is your eligibility towards permanentresidence...   \n",
       "...              ...                                                ...   \n",
       "5224           covid  love and kindness are never wasted beyondright...   \n",
       "4964           covid  people on my shit list for lying denying reali...   \n",
       "4339           covid  is there a connection between air pollution an...   \n",
       "251            covid  icymi the loser whos barricaded himself in the...   \n",
       "4598           covid  now is the time to start preparing your facili...   \n",
       "\n",
       "                                                 Hashtag  \n",
       "9890   [eijazkhan, bitcoin, blackpink, blockchain, fi...  \n",
       "839    [covidpiggybacking, coviduk, comorbidity, asym...  \n",
       "13282                [relief, businesses, relieffunding]  \n",
       "15000                                      [coronavirus]  \n",
       "13204                 [permanentresidence, covid19, pnp]  \n",
       "...                                                  ...  \n",
       "5224   [beyondrights, charity, nonprofit, donate, lov...  \n",
       "4964                                                  []  \n",
       "4339   [airpollution, pollution, covid19, coronavirus...  \n",
       "251                                                   []  \n",
       "4598   [facility, vaccine, drive, clinics, pharmacies...  \n",
       "\n",
       "[12000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle the data for Convenience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"covid.txt\", \"wb\") as handle : # write dataframe into text file\n",
    "  pickle.dump(covid_df, handle)\n",
    "with open(\"christmas.txt\", \"wb\") as handle : # write dataframe into text file\n",
    "  pickle.dump(christmas_df, handle)\n",
    "with open(\"spacex.txt\", \"wb\") as handle : # write dataframe into text file\n",
    "  pickle.dump(spacex_df, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (3.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
