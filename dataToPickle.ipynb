{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cheack whether an object (data) contains attribute (x) or not\n",
    "def check_var(data, x) :\n",
    "    try :\n",
    "        data[x]\n",
    "        return True\n",
    "    except :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to turn json into dataframe\n",
    "def json_to_df(file, hashtag) :\n",
    "# text and hashtags\n",
    "    count = 0\n",
    "    df_list = []\n",
    "    text_set = set()\n",
    "    with open(file, 'r', encoding = 'utf8') as f :\n",
    "        all_data = json.load(f)\n",
    "     \n",
    "        for data in all_data :\n",
    "            hashtag_list = [] # to collect list of hashtags\n",
    "            \n",
    "            # case 1: check whether it is a retweet data or not\n",
    "            if (check_var(data, 'retweeted_status')) :\n",
    "                \n",
    "                Text = data['retweeted_status']['full_text']\n",
    "                for t in data['retweeted_status']['entities']['hashtags'] :\n",
    "                    hashtag_list.append(t['text'])                \n",
    "\n",
    "                # check whether it is retweet of quoted tweet or not\n",
    "                if (check_var(data['retweeted_status'], 'quoted_status')) :\n",
    "                    Text = Text + ' || ' + data['retweeted_status']['quoted_status']['full_text']\n",
    "                    for t in data['retweeted_status']['entities']['hashtags'] :\n",
    "                        hashtag_list.append(t['text'])               \n",
    " \n",
    "            # case 2: check whether it is a quote tweet data or not\n",
    "            elif (check_var(data, 'quoted_status')) :\n",
    "                Text = data['full_text'] \n",
    "                Text = Text + ' || ' + data['quoted_status']['full_text']\n",
    "                for t in data['entities']['hashtags'] :\n",
    "                    hashtag_list.append(t['text'])\n",
    "                for t in data['quoted_status']['entities']['hashtags'] :\n",
    "                    hashtag_list.append(t['text'])\n",
    "\n",
    "            # if it does not belong to case 1 and case 2, it is an ordinary tweet data\n",
    "            else :\n",
    "\n",
    "                Text = data['full_text']\n",
    "                for t in data['entities']['hashtags'] :\n",
    "                    hashtag_list.append(t['text'])\n",
    "            \n",
    "            hashtag_list = [h.lower() for h in hashtag_list]\n",
    "            hashtag_list = list(filter(lambda h: h != hashtag, hashtag_list))      \n",
    "            \n",
    "            text_split = Text.lower().split()\n",
    "            #text_split = [x for x in text_split if x != '#' + hashtag] # remove our hashtag\n",
    "            text_split = [x for x in text_split if hashtag not in x]\n",
    "            text_split = [x for x in text_split if not x.startswith('http')] # remove link\n",
    "            text_split = [x for x in text_split if x != '\\n'] # remove new line character\n",
    "            Text = ' '.join(text_split)\n",
    "            \n",
    "            for h in hashtag_list :\n",
    "                Text = Text.replace('#' + h.lower(), h.lower())\n",
    "            \n",
    "            if Text not in text_set :\n",
    "                df_list.append((Text, hashtag_list))  \n",
    "                text_set.add(Text)\n",
    "\n",
    "    df = pd.DataFrame(df_list, columns = ['Text', 'Hashtag'])\n",
    "    df['Classification'] = [hashtag] * df.shape[0]\n",
    "    df = df[['Classification', 'Text', 'Hashtag']]\n",
    "                    \n",
    "    return df                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'covid-out-23K.json'\n",
    "covid_df = json_to_df(file, 'covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid</td>\n",
       "      <td>when i wonder how long we‚Äôll be in lockdown, i...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid</td>\n",
       "      <td>so.... if a cure for has been found in just a ...</td>\n",
       "      <td>[cancer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid</td>\n",
       "      <td>u.s deaths: 250,000-plus. (source: @johnshopki...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid</td>\n",
       "      <td>why schools closing and bars, restaurants and ...</td>\n",
       "      <td>[nyc, schools]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid</td>\n",
       "      <td>my great-aunt died this evening of at the age ...</td>\n",
       "      <td>[covid_19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>covid</td>\n",
       "      <td>1 panelist suggests in scheduling quick virtua...</td>\n",
       "      <td>[remoteworking]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>covid</td>\n",
       "      <td>allium vegetables for (sulfur) vegetable known...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>covid</td>\n",
       "      <td>the film ‚Äúcontagion‚Äù literally predicted every...</td>\n",
       "      <td>[covid19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>covid</td>\n",
       "      <td>anyone notice became the new fakenews msm topi...</td>\n",
       "      <td>[fakenews, msm, election, voterfraud, wednesda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>covid</td>\n",
       "      <td>@ksl5tv @pac12 @byufootball @utah_football @ks...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>covid</td>\n",
       "      <td>so oregon gov. katebrown's logic is if you hav...</td>\n",
       "      <td>[oregon, katebrown, thanksgiving, chinavirus, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>covid</td>\n",
       "      <td>donald trump's legacy.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>covid</td>\n",
       "      <td>several animal charities are warning against \"...</td>\n",
       "      <td>[breeders, kittens, puppies, facebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>covid</td>\n",
       "      <td>3 years of a crypto bear market made me have n...</td>\n",
       "      <td>[btc, bitcoin, cryptocurrency, xrp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>covid</td>\n",
       "      <td>whoa...i had to check my calendar, i thought i...</td>\n",
       "      <td>[nyc, schools, thisisourleadership, nolessonsl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>covid</td>\n",
       "      <td>@ufpharmacy honored to be part of the national...</td>\n",
       "      <td>[covid19, clinicaltrials]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>covid</td>\n",
       "      <td>yesterday it was a demonstration against slova...</td>\n",
       "      <td>[holocaust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>covid</td>\n",
       "      <td>900 mayo clinic employees have been infected w...</td>\n",
       "      <td>[mayo, rochestermn, minneapolis, fairmontmn, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>covid</td>\n",
       "      <td>the latest in hypocrisies üëáüèª no fines for pro-...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>covid</td>\n",
       "      <td>if you test negative for it doesn't mean you a...</td>\n",
       "      <td>[covid_19, covid19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classification                                               Text  \\\n",
       "0           covid  when i wonder how long we‚Äôll be in lockdown, i...   \n",
       "1           covid  so.... if a cure for has been found in just a ...   \n",
       "2           covid  u.s deaths: 250,000-plus. (source: @johnshopki...   \n",
       "3           covid  why schools closing and bars, restaurants and ...   \n",
       "4           covid  my great-aunt died this evening of at the age ...   \n",
       "5           covid  1 panelist suggests in scheduling quick virtua...   \n",
       "6           covid  allium vegetables for (sulfur) vegetable known...   \n",
       "7           covid  the film ‚Äúcontagion‚Äù literally predicted every...   \n",
       "8           covid  anyone notice became the new fakenews msm topi...   \n",
       "9           covid  @ksl5tv @pac12 @byufootball @utah_football @ks...   \n",
       "10          covid  so oregon gov. katebrown's logic is if you hav...   \n",
       "11          covid                             donald trump's legacy.   \n",
       "12          covid  several animal charities are warning against \"...   \n",
       "13          covid  3 years of a crypto bear market made me have n...   \n",
       "14          covid  whoa...i had to check my calendar, i thought i...   \n",
       "15          covid  @ufpharmacy honored to be part of the national...   \n",
       "16          covid  yesterday it was a demonstration against slova...   \n",
       "17          covid  900 mayo clinic employees have been infected w...   \n",
       "18          covid  the latest in hypocrisies üëáüèª no fines for pro-...   \n",
       "19          covid  if you test negative for it doesn't mean you a...   \n",
       "\n",
       "                                              Hashtag  \n",
       "0                                                  []  \n",
       "1                                            [cancer]  \n",
       "2                                                  []  \n",
       "3                                      [nyc, schools]  \n",
       "4                                          [covid_19]  \n",
       "5                                     [remoteworking]  \n",
       "6                                                  []  \n",
       "7                                           [covid19]  \n",
       "8   [fakenews, msm, election, voterfraud, wednesda...  \n",
       "9                                                  []  \n",
       "10  [oregon, katebrown, thanksgiving, chinavirus, ...  \n",
       "11                                                 []  \n",
       "12             [breeders, kittens, puppies, facebook]  \n",
       "13                [btc, bitcoin, cryptocurrency, xrp]  \n",
       "14  [nyc, schools, thisisourleadership, nolessonsl...  \n",
       "15                          [covid19, clinicaltrials]  \n",
       "16                                        [holocaust]  \n",
       "17  [mayo, rochestermn, minneapolis, fairmontmn, m...  \n",
       "18                                                 []  \n",
       "19                                [covid_19, covid19]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'christmas-out-23K.json'\n",
    "christmas_df = json_to_df(file, 'christmas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>christmas</td>\n",
       "      <td>is the perfect place for the holidays gift. su...</td>\n",
       "      <td>[coldpresssoap, bodyscrub, soap, soapmaking, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>christmas</td>\n",
       "      <td>follow &amp;amp; retweet for the chance to win a ¬£...</td>\n",
       "      <td>[competition, win]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christmas</td>\n",
       "      <td>it's winitwednesday! follow &amp;amp; rt @lauramar...</td>\n",
       "      <td>[winitwednesday, win, astreetcatnamedbob, comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christmas</td>\n",
       "      <td>there will be obstacles. there will be doubter...</td>\n",
       "      <td>[cryptocurrency, binary, motivation, investor,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>christmas</td>\n",
       "      <td>do you know how i plan to celebrate this year?...</td>\n",
       "      <td>[durgapuja, diwali]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>christmas</td>\n",
       "      <td>meet the couples of bells pass! shep &amp;amp; ivy...</td>\n",
       "      <td>[amreadingromance, christmasromance, ku, roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>christmas</td>\n",
       "      <td>üåüwinüåü we‚Äôre now taking orders for both instore...</td>\n",
       "      <td>[win, givingaway, prize, xmas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>christmas</td>\n",
       "      <td>november blog post for harlequin romance inclu...</td>\n",
       "      <td>[blog, harlequin, romance, reviews, romancerea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>christmas</td>\n",
       "      <td>look at what we're taste testing today @choice...</td>\n",
       "      <td>[mincepie, tasty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>christmas</td>\n",
       "      <td>if you are in @inglesadvantage get the $5 food...</td>\n",
       "      <td>[doyourpart, thanksgiving, christmasiscoming]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>christmas</td>\n",
       "      <td>who else is excited? we can watch a charlie br...</td>\n",
       "      <td>[charliebrown, thanksgiving]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>christmas</td>\n",
       "      <td>if shopping online this any time üéÖü§∂üéÑüá®üáΩ</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>christmas</td>\n",
       "      <td>don‚Äôt be a cotton headed ninny muggins. please...</td>\n",
       "      <td>[elf, holidays, thanksgiving, health, safetyfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>christmas</td>\n",
       "      <td>2 more kindereggs toys @ norwalk, connecticut</td>\n",
       "      <td>[kindereggs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>christmas</td>\n",
       "      <td>*** competition *** we're giving away a ¬£50 jo...</td>\n",
       "      <td>[competition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>christmas</td>\n",
       "      <td>having some time to kill ? dreaming of buildin...</td>\n",
       "      <td>[art, craft, diy, painting, gift, homedecor, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>christmas</td>\n",
       "      <td>are we going to have to cancel because santa i...</td>\n",
       "      <td>[covid19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>christmas</td>\n",
       "      <td>floral pattern with grunge background is an aw...</td>\n",
       "      <td>[floral, pattern, mask, grunge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>christmas</td>\n",
       "      <td>nobody will die from cancelling but more peopl...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>christmas</td>\n",
       "      <td>this christian art celebrates the most excitin...</td>\n",
       "      <td>[christian, art, printable, art, christianlivi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classification                                               Text  \\\n",
       "0       christmas  is the perfect place for the holidays gift. su...   \n",
       "1       christmas  follow &amp; retweet for the chance to win a ¬£...   \n",
       "2       christmas  it's winitwednesday! follow &amp; rt @lauramar...   \n",
       "3       christmas  there will be obstacles. there will be doubter...   \n",
       "4       christmas  do you know how i plan to celebrate this year?...   \n",
       "5       christmas  meet the couples of bells pass! shep &amp; ivy...   \n",
       "6       christmas  üåüwinüåü we‚Äôre now taking orders for both instore...   \n",
       "7       christmas  november blog post for harlequin romance inclu...   \n",
       "8       christmas  look at what we're taste testing today @choice...   \n",
       "9       christmas  if you are in @inglesadvantage get the $5 food...   \n",
       "10      christmas  who else is excited? we can watch a charlie br...   \n",
       "11      christmas             if shopping online this any time üéÖü§∂üéÑüá®üáΩ   \n",
       "12      christmas  don‚Äôt be a cotton headed ninny muggins. please...   \n",
       "13      christmas      2 more kindereggs toys @ norwalk, connecticut   \n",
       "14      christmas  *** competition *** we're giving away a ¬£50 jo...   \n",
       "15      christmas  having some time to kill ? dreaming of buildin...   \n",
       "16      christmas  are we going to have to cancel because santa i...   \n",
       "17      christmas  floral pattern with grunge background is an aw...   \n",
       "18      christmas  nobody will die from cancelling but more peopl...   \n",
       "19      christmas  this christian art celebrates the most excitin...   \n",
       "\n",
       "                                              Hashtag  \n",
       "0   [coldpresssoap, bodyscrub, soap, soapmaking, e...  \n",
       "1                                  [competition, win]  \n",
       "2   [winitwednesday, win, astreetcatnamedbob, comp...  \n",
       "3   [cryptocurrency, binary, motivation, investor,...  \n",
       "4                                 [durgapuja, diwali]  \n",
       "5   [amreadingromance, christmasromance, ku, roman...  \n",
       "6                      [win, givingaway, prize, xmas]  \n",
       "7   [blog, harlequin, romance, reviews, romancerea...  \n",
       "8                                   [mincepie, tasty]  \n",
       "9       [doyourpart, thanksgiving, christmasiscoming]  \n",
       "10                       [charliebrown, thanksgiving]  \n",
       "11                                                 []  \n",
       "12  [elf, holidays, thanksgiving, health, safetyfi...  \n",
       "13                                       [kindereggs]  \n",
       "14                                      [competition]  \n",
       "15  [art, craft, diy, painting, gift, homedecor, b...  \n",
       "16                                          [covid19]  \n",
       "17                    [floral, pattern, mask, grunge]  \n",
       "18                                                 []  \n",
       "19  [christian, art, printable, art, christianlivi...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "christmas_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'spacex-out-35K.json'\n",
    "spacex_df = json_to_df(file, 'spacex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spacex</td>\n",
       "      <td>the return of crew-1's booster, b1061.1. after...</td>\n",
       "      <td>[crew2, spacexfleet, crew1, launchamerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spacex</td>\n",
       "      <td>weather for nov 21st, at 10:17pm est | 7:17pm ...</td>\n",
       "      <td>[starlink, falcon9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spacex</td>\n",
       "      <td>@apompliano falcon 9 landing ~ by harv Â§ñ‰∫∫ @pun...</td>\n",
       "      <td>[nft, cryptoart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spacex</td>\n",
       "      <td>moonship crew section.üöÄüåí moonship</td>\n",
       "      <td>[moonship]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spacex</td>\n",
       "      <td>looks like the left leg's crush core wasn't th...</td>\n",
       "      <td>[spacexfleet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spacex</td>\n",
       "      <td>new development! starship sn9 nose cone forwar...</td>\n",
       "      <td>[bocachica, starship]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spacex</td>\n",
       "      <td>coming in febraury 2021 - just in time for the...</td>\n",
       "      <td>[mars, space, science, marssociety, nasa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spacex</td>\n",
       "      <td>simply beautiful! || view from the @space_stat...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spacex</td>\n",
       "      <td>i just really love this shit!</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spacex</td>\n",
       "      <td>: view from the @space_station of dragon‚Äòs app...</td>\n",
       "      <td>[space]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spacex</td>\n",
       "      <td>starship full flight animation. co-created wit...</td>\n",
       "      <td>[starship]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spacex</td>\n",
       "      <td>@emspeck @news6wkmg nasa &amp;amp; wanted that boo...</td>\n",
       "      <td>[nasa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spacex</td>\n",
       "      <td>booster 1061 returned to port canaveral after ...</td>\n",
       "      <td>[falcon9, crew1, spacexfleet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spacex</td>\n",
       "      <td>japan astronaut noguchi says ship offered \"bes...</td>\n",
       "      <td>[japan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spacex</td>\n",
       "      <td>sorry, i just had to. üòÜ</td>\n",
       "      <td>[spacexfleet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spacex</td>\n",
       "      <td>oh no</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spacex</td>\n",
       "      <td>test, learn, retool -- starship to undergo som...</td>\n",
       "      <td>[starship, moon, mars, nasa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spacex</td>\n",
       "      <td>has had 21 successful launches this year, tied...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spacex</td>\n",
       "      <td>i have no words to explain this feeling of see...</td>\n",
       "      <td>[vpelectkamalaharris, launchamerica, victorglo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spacex</td>\n",
       "      <td>today's banter bite thursdayvibes</td>\n",
       "      <td>[thursdayvibes]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classification                                               Text  \\\n",
       "0          spacex  the return of crew-1's booster, b1061.1. after...   \n",
       "1          spacex  weather for nov 21st, at 10:17pm est | 7:17pm ...   \n",
       "2          spacex  @apompliano falcon 9 landing ~ by harv Â§ñ‰∫∫ @pun...   \n",
       "3          spacex                  moonship crew section.üöÄüåí moonship   \n",
       "4          spacex  looks like the left leg's crush core wasn't th...   \n",
       "5          spacex  new development! starship sn9 nose cone forwar...   \n",
       "6          spacex  coming in febraury 2021 - just in time for the...   \n",
       "7          spacex  simply beautiful! || view from the @space_stat...   \n",
       "8          spacex                      i just really love this shit!   \n",
       "9          spacex  : view from the @space_station of dragon‚Äòs app...   \n",
       "10         spacex  starship full flight animation. co-created wit...   \n",
       "11         spacex  @emspeck @news6wkmg nasa &amp; wanted that boo...   \n",
       "12         spacex  booster 1061 returned to port canaveral after ...   \n",
       "13         spacex  japan astronaut noguchi says ship offered \"bes...   \n",
       "14         spacex                            sorry, i just had to. üòÜ   \n",
       "15         spacex                                              oh no   \n",
       "16         spacex  test, learn, retool -- starship to undergo som...   \n",
       "17         spacex  has had 21 successful launches this year, tied...   \n",
       "18         spacex  i have no words to explain this feeling of see...   \n",
       "19         spacex                  today's banter bite thursdayvibes   \n",
       "\n",
       "                                              Hashtag  \n",
       "0          [crew2, spacexfleet, crew1, launchamerica]  \n",
       "1                                 [starlink, falcon9]  \n",
       "2                                    [nft, cryptoart]  \n",
       "3                                          [moonship]  \n",
       "4                                       [spacexfleet]  \n",
       "5                               [bocachica, starship]  \n",
       "6           [mars, space, science, marssociety, nasa]  \n",
       "7                                                  []  \n",
       "8                                                  []  \n",
       "9                                             [space]  \n",
       "10                                         [starship]  \n",
       "11                                             [nasa]  \n",
       "12                      [falcon9, crew1, spacexfleet]  \n",
       "13                                            [japan]  \n",
       "14                                      [spacexfleet]  \n",
       "15                                                 []  \n",
       "16                       [starship, moon, mars, nasa]  \n",
       "17                                                 []  \n",
       "18  [vpelectkamalaharris, launchamerica, victorglo...  \n",
       "19                                    [thursdayvibes]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacex_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"covid.txt\", \"wb\") as handle : # write dataframe into text file\n",
    "  pickle.dump(covid_df, handle)\n",
    "with open(\"christmas.txt\", \"wb\") as handle : # write dataframe into text file\n",
    "  pickle.dump(christmas_df, handle)\n",
    "with open(\"spacex.txt\", \"wb\") as handle : # write dataframe into text file\n",
    "  pickle.dump(spacex_df, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 3 in Python 3 (3.8)",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
